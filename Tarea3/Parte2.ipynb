{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de galaxias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta tarea es hacer una red neuronal que pueda diferenciar entre tres tipos de galaxia: espiral, irregular y elíptica. Se va a hacer por medio de una red convolucional (para disminuír el número de parámetros de la red.\n",
    "\n",
    "El ejercicio está basado en el [tutorial](https://www.tensorflow.org/tutorials/layers) de tensorflow para capas en una red convolutiva.\n",
    "\n",
    "Las fotos de estas galaxias las necesitan sacar del folder zip que se llame 'source' (basta con darle click derecho y luego descomprimir, en realidad.\n",
    "\n",
    "Primero lo primero, cargar las bibliotecas necesarias. Recuerden, si una les aparece que no está instalada, basta con que utilicen el ambiente virtual para instalar cosas. En particular, tensorflow y PIL (cuyo paquete se llama Pillow, es decir, `pip install pillow`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a cargar en RAM todas las fotos. Para ello primero cargamos los nombres y sus tipos (lo único que nos interesa). Me aprovecho de ello para de una vez guardar en un data frame sólo las columnas de interés. No sólo eso pero de una vez vamos a convertir las etiquetas en las tres posibilidades de galaxia que nos interesa clasificar: Elíptica ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"EFIGI_data.txt\")\n",
    "numToGalaxy = {0: 'Eliptica', 1: 'Espiral', 2: 'Irregular'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhotoName</th>\n",
       "      <th>HStage</th>\n",
       "      <th>Type</th>\n",
       "      <th>NType</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PGC0009530</td>\n",
       "      <td>10</td>\n",
       "      <td>I</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PGC0025524</td>\n",
       "      <td>-5</td>\n",
       "      <td>E</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PGC0002149</td>\n",
       "      <td>-3</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PGC0004363</td>\n",
       "      <td>-3</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PGC0004540</td>\n",
       "      <td>6</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PhotoName  HStage Type  NType\n",
       "0  PGC0009530      10    I      2\n",
       "1  PGC0025524      -5    E      0\n",
       "2  PGC0002149      -3    S      1\n",
       "3  PGC0004363      -3    S      1\n",
       "4  PGC0004540       6    S      1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esperemos tener una distribución masomenos equitativa de cada galaxia. Usando `groupby` podremos verificar esto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PhotoName</th>\n",
       "      <th>HStage</th>\n",
       "      <th>NType</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>E</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S</th>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      PhotoName  HStage  NType\n",
       "Type                          \n",
       "E           200     200    200\n",
       "I           200     200    200\n",
       "S           200     200    200"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"Type\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pues... Resulta que no. En fin, A la mejor el problema fue dar un rango tan grande a las espirales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HStage\n",
       "-6      14\n",
       "-5     163\n",
       "-4      23\n",
       "-3      18\n",
       "-2      14\n",
       "-1       7\n",
       " 0       6\n",
       " 1      19\n",
       " 2      14\n",
       " 3      18\n",
       " 4      14\n",
       " 5       8\n",
       " 6      31\n",
       " 7      15\n",
       " 8      27\n",
       " 9       9\n",
       " 10    156\n",
       " 11     44\n",
       "Name: Type, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby(\"HStage\").count().Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si pues, un poco más homogeneo... Tenemos aún que cargar 82MB de imágenes en RAM. Esto puede ser un grave problema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 65025)\n"
     ]
    }
   ],
   "source": [
    "# From the dataframe, we make a list of images\n",
    "images = []\n",
    "\n",
    "images = data.apply(lambda row: Image.open(os.path.join('source',row.PhotoName+'.png')).convert('L'), axis = 1)\n",
    "shape = [images[0].height, images[0].width]\n",
    "# To normalized numpy array\n",
    "images = np.array(\n",
    "    list(map(lambda pic: np.reshape(np.array(pic), [1, pic.width * pic.height])[0] , images)), dtype = 'float32'\n",
    ") / 255\n",
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente bloque es la parte clave: esriba la estructura de redes convolucionales interna para procesar cada imagen. La última capa y la primer capa ya están hechas. De por medio puede utilizar _pooling_, _flattening_, redes de conexión completa o convoluciones. Como sugerencia: use 2 filtros de 8x8 (convoluciones), luego haga pooling de 3x3 al resultado, luego puede aplanar el resultado y hacer alguna red pequeña de conexión completa con probabilidad de dejar caer algunas aristas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model_fn(features, labels, mode):\n",
    "    \"\"\"Model function for CNN.\"\"\"\n",
    "    \n",
    "    # Input Layer, regresamos las imagenes a su dimensión\n",
    "    input_layer = tf.reshape(features[\"x\"], [-1, shape[0], shape[1], 1])\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### AQUÍ TODAS LAS CONEXIONES INTERMEDIAS ###\n",
    "    lastLayer = tf.contrib.layers.flatten(input_layer)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logits Layer, ternary classification\n",
    "    logits = tf.layers.dense(inputs=lastLayer, units=3)\n",
    "\n",
    "    predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "    }\n",
    "\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "    # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "    # Configure the Training Op (for TRAIN mode)\n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "        train_op = optimizer.minimize(\n",
    "            loss=loss,\n",
    "            global_step=tf.train.get_global_step())\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "    # Add evaluation metrics (for EVAL mode)\n",
    "    eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora ponemos el estimador. Como nota, el folder tmp se debe borrar para cada nuevo modelo que se haga, o el entrenamiento continuará desde el último valor de los pesos de cada arista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/cs_model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f56df1eaf98>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "# Se crea ahora el estimador, en un folder llamado tmp\n",
    "cs_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir=\"./tmp/cs_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aquí se hace el entrenamiento, vaya por un número de repeticiones coherente. El argumento batch_size es el número de fotos que se usarán para calcular el gradiente para cada paso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of 599 which is outside the valid range of [0, 3).  Label values: 127 542 51 391 436 583 431 119 153 275 525 425 539 271 380 203 460 141 339 139 243 7 253 371 190 526 588 435 585 43 499 308 365 400 528 504 524 518 92 423 568 56 268 593 334 61 105 122 475 291 343 536 38 404 130 561 599 200 73 538 48 155 471 209 102 146 545 595 193 154 557 414 88 293 75 420 90 304 140 483 439 529 34 177 284 160 444 115 338 192 47 419 448 128 378 541 247 278 480 418 554 458 452 446 28 220 255 508 372 385 292 510 581 223 241 230 166 64 179 14 505 136 537 50 346 183 267 91 468 535 407 23 250 434 490 412 443 5 12 232 199 143 87 472 402 103 59 326 294 313 302 1 488 355 379 516 357 578 316 459 487 579 565 566 65 534 234 411 470 298 198 368 164 562 314 421 405 224 225 82 496 401 486 367 464 558 245 430 438 413 493 495 341 373 67 211 100 381 328 399 58 85 257 273 219 416 533 330 360 258 260 280 492 158 81 180 265 498 342 266 104 222 417 428 395 46 106 522 79 147 594 447 467 354 210 235 331 212 489 530 299 340 63 126 320 563 323 101 589 129 426 321 263 168 361 197 21 52 315 236 532 110 465 286 120 353 11 31 30 509 186 285 270 202 523 478 569 173 13 441 239 69 89 112 349 592 72 191 145 390 36 37 287 453 455 256 172 95 469 161 501 521 456 254 259 132 564 189 80 289 208 252 503 121 450 251 389 350 217 264 277 319 9 77 86 249 142 184 10 573 409 272 587 440 24 392 162 520 41 457 114 97 0 84 195 123 201 32 4 574 331 484 582 38 398 325 332 55 463 451 387 342 159 45 235 501 444 110 544 140 506 102 76 580 515 20 474 530 35 290 406 584 150 498 540 431 475 8 74 521 445 586 22 321 317 547 523 80 105 306 254 505 347 90 15 253 546 353 49 16 304 0 17 36 251 479 364 12 219 159 98 442 187 309 279 5 411 575 151 301 188 39 468 384 363 270 445 345 437 488 370 327 124 156 93 403 227 31 47 389 354 178 450 92 535 565 198 81 576 408 404 429 231 436 541 89 493 135 248 56 464 238 167 163 406 128 524 108 138 213 430 517 134 41 525 423 83 184 300 269 157 580 180 288 172 301 148 50 499 326 341 152 577 427 319 452 364 531 522 87 334 303 229 349 291 320 244 218 572 415 157 76 75 417 360 596 496 210 178 310 459 540 121 276 118 328 168 352 237 348 91 533 2 338 215 587 125 1 170 409 71 143 72 135 207 598 357 286 275 17 494 130 252 247 96 174 386 442 144 312 422 351 463 441 568 506 176 297 195 484 336 473 282 563 205 314 572 297 497 242 296 125 550 575 284 96 61 111 170 395\n\t [[Node: sparse_softmax_cross_entropy_loss/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/BiasAdd, random_shuffle_queue_DequeueMany:2)]]\n\nCaused by op 'sparse_softmax_cross_entropy_loss/xentropy/xentropy', defined at:\n  File \"/home/ivan/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ivan/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-116-439a24a9219c>\", line 8, in <module>\n    cs_classifier.train(input_fn=train_input_fn,steps=1)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 843, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 856, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-68-58b6783e6130>\", line 29, in cnn_model_fn\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py\", line 853, in sparse_softmax_cross_entropy\n    name=\"xentropy\")\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2050, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7479, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of 599 which is outside the valid range of [0, 3).  Label values: 127 542 51 391 436 583 431 119 153 275 525 425 539 271 380 203 460 141 339 139 243 7 253 371 190 526 588 435 585 43 499 308 365 400 528 504 524 518 92 423 568 56 268 593 334 61 105 122 475 291 343 536 38 404 130 561 599 200 73 538 48 155 471 209 102 146 545 595 193 154 557 414 88 293 75 420 90 304 140 483 439 529 34 177 284 160 444 115 338 192 47 419 448 128 378 541 247 278 480 418 554 458 452 446 28 220 255 508 372 385 292 510 581 223 241 230 166 64 179 14 505 136 537 50 346 183 267 91 468 535 407 23 250 434 490 412 443 5 12 232 199 143 87 472 402 103 59 326 294 313 302 1 488 355 379 516 357 578 316 459 487 579 565 566 65 534 234 411 470 298 198 368 164 562 314 421 405 224 225 82 496 401 486 367 464 558 245 430 438 413 493 495 341 373 67 211 100 381 328 399 58 85 257 273 219 416 533 330 360 258 260 280 492 158 81 180 265 498 342 266 104 222 417 428 395 46 106 522 79 147 594 447 467 354 210 235 331 212 489 530 299 340 63 126 320 563 323 101 589 129 426 321 263 168 361 197 21 52 315 236 532 110 465 286 120 353 11 31 30 509 186 285 270 202 523 478 569 173 13 441 239 69 89 112 349 592 72 191 145 390 36 37 287 453 455 256 172 95 469 161 501 521 456 254 259 132 564 189 80 289 208 252 503 121 450 251 389 350 217 264 277 319 9 77 86 249 142 184 10 573 409 272 587 440 24 392 162 520 41 457 114 97 0 84 195 123 201 32 4 574 331 484 582 38 398 325 332 55 463 451 387 342 159 45 235 501 444 110 544 140 506 102 76 580 515 20 474 530 35 290 406 584 150 498 540 431 475 8 74 521 445 586 22 321 317 547 523 80 105 306 254 505 347 90 15 253 546 353 49 16 304 0 17 36 251 479 364 12 219 159 98 442 187 309 279 5 411 575 151 301 188 39 468 384 363 270 445 345 437 488 370 327 124 156 93 403 227 31 47 389 354 178 450 92 535 565 198 81 576 408 404 429 231 436 541 89 493 135 248 56 464 238 167 163 406 128 524 108 138 213 430 517 134 41 525 423 83 184 300 269 157 580 180 288 172 301 148 50 499 326 341 152 577 427 319 452 364 531 522 87 334 303 229 349 291 320 244 218 572 415 157 76 75 417 360 596 496 210 178 310 459 540 121 276 118 328 168 352 237 348 91 533 2 338 215 587 125 1 170 409 71 143 72 135 207 598 357 286 275 17 494 130 252 247 96 174 386 442 144 312 422 351 463 441 568 506 176 297 195 484 336 473 282 563 205 314 572 297 497 242 296 125 550 575 284 96 61 111 170 395\n\t [[Node: sparse_softmax_cross_entropy_loss/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/BiasAdd, random_shuffle_queue_DequeueMany:2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1307\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m           run_metadata)\n\u001b[0m\u001b[1;32m   1410\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 599 which is outside the valid range of [0, 3).  Label values: 127 542 51 391 436 583 431 119 153 275 525 425 539 271 380 203 460 141 339 139 243 7 253 371 190 526 588 435 585 43 499 308 365 400 528 504 524 518 92 423 568 56 268 593 334 61 105 122 475 291 343 536 38 404 130 561 599 200 73 538 48 155 471 209 102 146 545 595 193 154 557 414 88 293 75 420 90 304 140 483 439 529 34 177 284 160 444 115 338 192 47 419 448 128 378 541 247 278 480 418 554 458 452 446 28 220 255 508 372 385 292 510 581 223 241 230 166 64 179 14 505 136 537 50 346 183 267 91 468 535 407 23 250 434 490 412 443 5 12 232 199 143 87 472 402 103 59 326 294 313 302 1 488 355 379 516 357 578 316 459 487 579 565 566 65 534 234 411 470 298 198 368 164 562 314 421 405 224 225 82 496 401 486 367 464 558 245 430 438 413 493 495 341 373 67 211 100 381 328 399 58 85 257 273 219 416 533 330 360 258 260 280 492 158 81 180 265 498 342 266 104 222 417 428 395 46 106 522 79 147 594 447 467 354 210 235 331 212 489 530 299 340 63 126 320 563 323 101 589 129 426 321 263 168 361 197 21 52 315 236 532 110 465 286 120 353 11 31 30 509 186 285 270 202 523 478 569 173 13 441 239 69 89 112 349 592 72 191 145 390 36 37 287 453 455 256 172 95 469 161 501 521 456 254 259 132 564 189 80 289 208 252 503 121 450 251 389 350 217 264 277 319 9 77 86 249 142 184 10 573 409 272 587 440 24 392 162 520 41 457 114 97 0 84 195 123 201 32 4 574 331 484 582 38 398 325 332 55 463 451 387 342 159 45 235 501 444 110 544 140 506 102 76 580 515 20 474 530 35 290 406 584 150 498 540 431 475 8 74 521 445 586 22 321 317 547 523 80 105 306 254 505 347 90 15 253 546 353 49 16 304 0 17 36 251 479 364 12 219 159 98 442 187 309 279 5 411 575 151 301 188 39 468 384 363 270 445 345 437 488 370 327 124 156 93 403 227 31 47 389 354 178 450 92 535 565 198 81 576 408 404 429 231 436 541 89 493 135 248 56 464 238 167 163 406 128 524 108 138 213 430 517 134 41 525 423 83 184 300 269 157 580 180 288 172 301 148 50 499 326 341 152 577 427 319 452 364 531 522 87 334 303 229 349 291 320 244 218 572 415 157 76 75 417 360 596 496 210 178 310 459 540 121 276 118 328 168 352 237 348 91 533 2 338 215 587 125 1 170 409 71 143 72 135 207 598 357 286 275 17 494 130 252 247 96 174 386 442 144 312 422 351 463 441 568 506 176 297 195 484 336 473 282 563 205 314 572 297 497 242 296 125 550 575 284 96 61 111 170 395\n\t [[Node: sparse_softmax_cross_entropy_loss/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/BiasAdd, random_shuffle_queue_DequeueMany:2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-116-439a24a9219c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     shuffle=True)\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mcs_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_input_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 363\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    841\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m    857\u001b[0m       return self._train_with_estimator_spec(estimator_spec, worker_hooks,\n\u001b[1;32m    858\u001b[0m                                              \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step_tensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                                              saving_listeners)\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_with_estimator_spec\u001b[0;34m(self, estimator_spec, worker_hooks, hooks, global_step_tensor, saving_listeners)\u001b[0m\n\u001b[1;32m   1057\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m       \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1059\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmon_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1060\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    565\u001b[0m                           \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                           \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 567\u001b[0;31m                           run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m    568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    569\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                               \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                               run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1044\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m         logging.info('An error was raised. This may be due to a preemption in '\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreraise\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0moriginal_exc_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/six.py\u001b[0m in \u001b[0;36mreraise\u001b[0;34m(tp, value, tb)\u001b[0m\n\u001b[1;32m    691\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 693\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    694\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1117\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1120\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_PREEMPTION_ERRORS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1121\u001b[0m       \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1189\u001b[0m                                   \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m                                   \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m                                   run_metadata=run_metadata)\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/monitored_session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 971\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    972\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    973\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mrun_step_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_with_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 900\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    901\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1135\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1136\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1316\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1317\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1335\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1337\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Received a label value of 599 which is outside the valid range of [0, 3).  Label values: 127 542 51 391 436 583 431 119 153 275 525 425 539 271 380 203 460 141 339 139 243 7 253 371 190 526 588 435 585 43 499 308 365 400 528 504 524 518 92 423 568 56 268 593 334 61 105 122 475 291 343 536 38 404 130 561 599 200 73 538 48 155 471 209 102 146 545 595 193 154 557 414 88 293 75 420 90 304 140 483 439 529 34 177 284 160 444 115 338 192 47 419 448 128 378 541 247 278 480 418 554 458 452 446 28 220 255 508 372 385 292 510 581 223 241 230 166 64 179 14 505 136 537 50 346 183 267 91 468 535 407 23 250 434 490 412 443 5 12 232 199 143 87 472 402 103 59 326 294 313 302 1 488 355 379 516 357 578 316 459 487 579 565 566 65 534 234 411 470 298 198 368 164 562 314 421 405 224 225 82 496 401 486 367 464 558 245 430 438 413 493 495 341 373 67 211 100 381 328 399 58 85 257 273 219 416 533 330 360 258 260 280 492 158 81 180 265 498 342 266 104 222 417 428 395 46 106 522 79 147 594 447 467 354 210 235 331 212 489 530 299 340 63 126 320 563 323 101 589 129 426 321 263 168 361 197 21 52 315 236 532 110 465 286 120 353 11 31 30 509 186 285 270 202 523 478 569 173 13 441 239 69 89 112 349 592 72 191 145 390 36 37 287 453 455 256 172 95 469 161 501 521 456 254 259 132 564 189 80 289 208 252 503 121 450 251 389 350 217 264 277 319 9 77 86 249 142 184 10 573 409 272 587 440 24 392 162 520 41 457 114 97 0 84 195 123 201 32 4 574 331 484 582 38 398 325 332 55 463 451 387 342 159 45 235 501 444 110 544 140 506 102 76 580 515 20 474 530 35 290 406 584 150 498 540 431 475 8 74 521 445 586 22 321 317 547 523 80 105 306 254 505 347 90 15 253 546 353 49 16 304 0 17 36 251 479 364 12 219 159 98 442 187 309 279 5 411 575 151 301 188 39 468 384 363 270 445 345 437 488 370 327 124 156 93 403 227 31 47 389 354 178 450 92 535 565 198 81 576 408 404 429 231 436 541 89 493 135 248 56 464 238 167 163 406 128 524 108 138 213 430 517 134 41 525 423 83 184 300 269 157 580 180 288 172 301 148 50 499 326 341 152 577 427 319 452 364 531 522 87 334 303 229 349 291 320 244 218 572 415 157 76 75 417 360 596 496 210 178 310 459 540 121 276 118 328 168 352 237 348 91 533 2 338 215 587 125 1 170 409 71 143 72 135 207 598 357 286 275 17 494 130 252 247 96 174 386 442 144 312 422 351 463 441 568 506 176 297 195 484 336 473 282 563 205 314 572 297 497 242 296 125 550 575 284 96 61 111 170 395\n\t [[Node: sparse_softmax_cross_entropy_loss/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/BiasAdd, random_shuffle_queue_DequeueMany:2)]]\n\nCaused by op 'sparse_softmax_cross_entropy_loss/xentropy/xentropy', defined at:\n  File \"/home/ivan/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/ivan/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2808, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-116-439a24a9219c>\", line 8, in <module>\n    cs_classifier.train(input_fn=train_input_fn,steps=1)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 363, in train\n    loss = self._train_model(input_fn, hooks, saving_listeners)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 843, in _train_model\n    return self._train_model_default(input_fn, hooks, saving_listeners)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 856, in _train_model_default\n    features, labels, model_fn_lib.ModeKeys.TRAIN, self.config)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\", line 831, in _call_model_fn\n    model_fn_results = self._model_fn(features=features, **kwargs)\n  File \"<ipython-input-68-58b6783e6130>\", line 29, in cnn_model_fn\n    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py\", line 853, in sparse_softmax_cross_entropy\n    name=\"xentropy\")\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/nn_ops.py\", line 2050, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_nn_ops.py\", line 7479, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"/home/ivan/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of 599 which is outside the valid range of [0, 3).  Label values: 127 542 51 391 436 583 431 119 153 275 525 425 539 271 380 203 460 141 339 139 243 7 253 371 190 526 588 435 585 43 499 308 365 400 528 504 524 518 92 423 568 56 268 593 334 61 105 122 475 291 343 536 38 404 130 561 599 200 73 538 48 155 471 209 102 146 545 595 193 154 557 414 88 293 75 420 90 304 140 483 439 529 34 177 284 160 444 115 338 192 47 419 448 128 378 541 247 278 480 418 554 458 452 446 28 220 255 508 372 385 292 510 581 223 241 230 166 64 179 14 505 136 537 50 346 183 267 91 468 535 407 23 250 434 490 412 443 5 12 232 199 143 87 472 402 103 59 326 294 313 302 1 488 355 379 516 357 578 316 459 487 579 565 566 65 534 234 411 470 298 198 368 164 562 314 421 405 224 225 82 496 401 486 367 464 558 245 430 438 413 493 495 341 373 67 211 100 381 328 399 58 85 257 273 219 416 533 330 360 258 260 280 492 158 81 180 265 498 342 266 104 222 417 428 395 46 106 522 79 147 594 447 467 354 210 235 331 212 489 530 299 340 63 126 320 563 323 101 589 129 426 321 263 168 361 197 21 52 315 236 532 110 465 286 120 353 11 31 30 509 186 285 270 202 523 478 569 173 13 441 239 69 89 112 349 592 72 191 145 390 36 37 287 453 455 256 172 95 469 161 501 521 456 254 259 132 564 189 80 289 208 252 503 121 450 251 389 350 217 264 277 319 9 77 86 249 142 184 10 573 409 272 587 440 24 392 162 520 41 457 114 97 0 84 195 123 201 32 4 574 331 484 582 38 398 325 332 55 463 451 387 342 159 45 235 501 444 110 544 140 506 102 76 580 515 20 474 530 35 290 406 584 150 498 540 431 475 8 74 521 445 586 22 321 317 547 523 80 105 306 254 505 347 90 15 253 546 353 49 16 304 0 17 36 251 479 364 12 219 159 98 442 187 309 279 5 411 575 151 301 188 39 468 384 363 270 445 345 437 488 370 327 124 156 93 403 227 31 47 389 354 178 450 92 535 565 198 81 576 408 404 429 231 436 541 89 493 135 248 56 464 238 167 163 406 128 524 108 138 213 430 517 134 41 525 423 83 184 300 269 157 580 180 288 172 301 148 50 499 326 341 152 577 427 319 452 364 531 522 87 334 303 229 349 291 320 244 218 572 415 157 76 75 417 360 596 496 210 178 310 459 540 121 276 118 328 168 352 237 348 91 533 2 338 215 587 125 1 170 409 71 143 72 135 207 598 357 286 275 17 494 130 252 247 96 174 386 442 144 312 422 351 463 441 568 506 176 297 195 484 336 473 282 563 205 314 572 297 497 242 296 125 550 575 284 96 61 111 170 395\n\t [[Node: sparse_softmax_cross_entropy_loss/xentropy/xentropy = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense/BiasAdd, random_shuffle_queue_DequeueMany:2)]]\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": images},\n",
    "    y = np.array([i for i in range(len(images))]),\n",
    "    batch_size=len(images),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)\n",
    "cs_classifier.train(input_fn=train_input_fn,steps=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, para hacer una pequeña prueba y que puedan ver su red funcionando, el siguiente bloque de código carga una imagen de manera aleatoria, y les dice qué tipo de galaxia es (la que su red debería predecir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La clasificación de la galaxia es Espiral\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(0,600)\n",
    "testImg = Image.open(os.path.join('source',data.PhotoName[idx]+'.png')).convert('L')\n",
    "imshow(testImg)\n",
    "print('La clasificación de la galaxia es ' + numToGalaxy[data.NType[idx]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este bloque que viene adelante, ejecuta la red para hacer una sola predicción. `pred` es una lista que contiene las probabilidades de cada clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not find trained model in model_dir: ./tmp/cs_model.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-118-bf9d3b023b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshuffle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcs_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict_input_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Predicciones: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m       raise ValueError('Could not find trained model in model_dir: {}.'.format(\n\u001b[0;32m--> 488\u001b[0;31m           self._model_dir))\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Could not find trained model in model_dir: ./tmp/cs_model."
     ]
    }
   ],
   "source": [
    "X = np.reshape(np.array(testImg,dtype = 'float32'), [1, testImg.width * testImg.height])[0] / 255\n",
    "\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'x': np.reshape(X, [1, -1]).astype('float32')},\n",
    "    shuffle = False\n",
    ")\n",
    "pred = list(cs_classifier.predict(input_fn = predict_input_fn))\n",
    "\n",
    "print('Predicciones: {}'.format(str(pred)))\n",
    "print('Debieramos tener una galaxia ' + numToGalaxy[pred[0]['classes']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Paso último y más difícil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Busque, google o stackoverflow, cómo hacer una validación cruazada para su red neuronal. Usted tiene 600 fotos, separe 40 de cada grupo para tener 80% de la información para entrenamiento y 20% para hacer una prueba.\n",
    "\n",
    "Lo puede hacer de manera manual separando la información en 5 bloques, y entrenando con las 5 posibles permutaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
